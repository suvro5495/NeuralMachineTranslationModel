{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This is just a simple translation using tensorflow"
      ],
      "metadata": {
        "id": "wgeKLrPBr-x-"
      }
    },
    {
      "source": [
        "!pip install tensorflow\n",
        "!pip install tensorflow_hub"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lnduzhp6j_Cb",
        "outputId": "fce8aecb-7bc1-44fe-ab57-36ea7ccd7212"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.9.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.60.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: tensorflow_hub in /usr/local/lib/python3.10/dist-packages (0.16.1)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_hub) (1.25.2)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow_hub) (3.20.3)\n",
            "Requirement already satisfied: tf-keras>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow_hub) (2.15.0)\n"
          ]
        }
      ]
    },
    {
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "kNtFyunjj_pZ"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "source": [
        "# Load the pre-trained model\n",
        "model = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "82psIaI8kAK_"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "source": [
        "# Prepare the input text\n",
        "input_text = tf.constant([\"This is a test sentence.\"])"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "xJE41d1AkAdD"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "source": [
        "# Translate the input text\n",
        "translated_text = model(input_text)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "jQ-yZw_4kBDN"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "source": [
        "# Print the translated text\n",
        "print(translated_text)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkRhruKfkBUR",
        "outputId": "444b499b-cfa9-4d78-ab09-6a85ed04c4c8"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 4.74886075e-02 -4.98664305e-02 -1.71142798e-02  2.99241040e-02\n",
            "  -5.26666492e-02 -5.95821179e-02  6.11432735e-03  3.35058942e-02\n",
            "   4.44955453e-02  3.38426754e-02  1.85408853e-02 -4.16645296e-02\n",
            "   7.37075880e-02  5.72554395e-02  1.80599913e-02 -7.43023753e-02\n",
            "   2.06891284e-03  4.64502871e-02  4.52925861e-02 -8.28705132e-02\n",
            "  -1.68106088e-03  5.97309731e-02 -6.28478751e-02  1.11337891e-02\n",
            "  -6.62655532e-02  3.79015058e-02 -9.23611596e-03 -5.67900389e-02\n",
            "   1.12583283e-02 -5.01601472e-02  5.57581894e-02 -4.20861840e-02\n",
            "   1.50783211e-02 -1.50357671e-02 -6.93174526e-02 -1.72347855e-03\n",
            "   7.31806410e-03 -2.83883624e-02  3.56385820e-02  6.78013265e-02\n",
            "  -2.56217755e-02  1.15059121e-02  1.65836699e-02  5.62694445e-02\n",
            "  -3.36205587e-02 -9.90155619e-03 -1.87957827e-02 -1.58994086e-02\n",
            "  -6.90774701e-04  1.12931561e-02  4.27371860e-02 -6.07277751e-02\n",
            "  -9.51165557e-02 -2.31154151e-02  1.43807447e-02 -4.02030163e-02\n",
            "   6.97867423e-02 -3.61778662e-02 -3.99746299e-02  4.51778844e-02\n",
            "  -7.66319502e-03 -8.92282650e-02  4.64384556e-02 -6.76325783e-02\n",
            "  -1.56667978e-02 -6.10811934e-02 -4.24425341e-02 -1.38226142e-02\n",
            "   6.08159713e-02 -3.51363532e-02  1.40826553e-02 -2.03604363e-02\n",
            "   6.59333542e-02  1.06248036e-02 -6.45249858e-02 -7.57094531e-04\n",
            "  -5.35058044e-02  9.19928867e-03  2.36289650e-02 -3.71559453e-03\n",
            "   7.28797466e-02  2.46678125e-02 -3.21651027e-02  5.77668175e-02\n",
            "   4.88600181e-03 -6.32847147e-03 -3.27127166e-02 -4.31515947e-02\n",
            "  -5.44366091e-02 -7.46360281e-03 -2.42220541e-03  6.97813779e-02\n",
            "  -3.53451399e-03  6.72078058e-02  3.47563885e-02  8.40087384e-02\n",
            "  -1.01306327e-01  3.00527550e-02 -7.73705309e-04 -1.85647681e-02\n",
            "   3.38358060e-02 -1.28875272e-02 -1.75100919e-02 -2.72519812e-02\n",
            "  -1.52036559e-03 -8.49263463e-03 -3.10102180e-02 -5.00368187e-03\n",
            "  -5.13134487e-02 -2.70090289e-02 -6.13897517e-02  4.08482924e-02\n",
            "  -1.79020669e-02  2.01148447e-02  1.38943512e-02 -8.00204277e-02\n",
            "  -2.60207932e-02 -2.63607055e-02  4.14546505e-02  4.64244485e-02\n",
            "   1.25692261e-03  5.49164452e-02 -1.97556112e-02 -2.75056846e-02\n",
            "  -1.90899521e-02  4.02063243e-02 -1.61142275e-02  2.19663791e-02\n",
            "  -5.81716013e-04 -1.69989653e-02  2.60158349e-02  3.84861454e-02\n",
            "   2.81938165e-02  7.54169328e-03 -4.56976937e-03 -1.43054193e-02\n",
            "   2.41842493e-02 -7.68522099e-02 -1.07379772e-01 -4.67368364e-02\n",
            "   1.49921607e-02 -8.54546651e-02  4.55315821e-02 -4.45153527e-02\n",
            "  -7.11856931e-02 -9.97517537e-03  8.91959481e-03 -9.04265419e-03\n",
            "   2.51712035e-02  3.97234876e-03  9.89905745e-02 -6.34814501e-02\n",
            "  -3.31366137e-02  2.19873767e-02  1.21777859e-02 -5.58172129e-02\n",
            "   3.58625799e-02 -1.15796400e-04  4.73058373e-02  2.66541187e-02\n",
            "  -2.14222237e-03 -1.49097852e-02  1.39273638e-02  5.99560514e-02\n",
            "  -7.19946772e-02  6.99537322e-02 -2.00972743e-02  5.07220514e-02\n",
            "  -4.73337574e-03 -5.18279858e-02  1.65831130e-02  3.91227454e-02\n",
            "  -1.82503052e-02 -1.84730105e-02 -6.84317760e-03  6.59847185e-02\n",
            "   4.37931269e-02  7.32945800e-02  1.55988820e-02  1.91385690e-02\n",
            "   4.87734675e-02  1.05777485e-02  3.89387608e-02 -3.90095729e-03\n",
            "   2.69360635e-02  7.31670186e-02  7.20018819e-02  1.53803052e-02\n",
            "  -7.35049322e-02 -1.08934157e-02  1.09343685e-01  8.88911821e-03\n",
            "   6.49444684e-02  1.24243172e-02  1.43623184e-02 -4.28589433e-02\n",
            "   2.23420393e-02  3.30762751e-02  1.10820886e-02  8.05073380e-02\n",
            "  -9.00020301e-02  5.46074621e-02  4.00385325e-04 -4.26393785e-02\n",
            "   8.60943124e-02 -6.83976784e-02  5.45199402e-02 -1.27826398e-02\n",
            "   9.77772474e-03  2.24030279e-02 -3.65690403e-02 -7.63267977e-03\n",
            "  -5.08439466e-02  3.39811444e-02  1.00327935e-02 -8.24236274e-02\n",
            "   1.94486044e-02  1.92108285e-02  8.92840028e-02  4.48599607e-02\n",
            "  -2.50298772e-02 -3.95745263e-02  1.74236186e-02 -2.99865343e-02\n",
            "  -1.57028083e-02 -4.54839803e-02 -7.04293372e-03  4.32149284e-02\n",
            "   2.50909682e-02 -4.31457050e-02 -4.56744917e-02  3.42962611e-03\n",
            "  -3.07565113e-03  1.13871388e-01  6.79278374e-03  1.63173936e-02\n",
            "   3.65208760e-02  1.37759252e-02  1.26695447e-02 -2.71371491e-02\n",
            "   8.46277084e-03  1.14480164e-02  3.54742259e-02 -1.06056398e-02\n",
            "  -7.22588366e-03 -9.11059882e-03  5.79773169e-03 -1.02932779e-02\n",
            "   8.20878893e-02  1.99706294e-02  1.37926126e-02 -4.57960926e-03\n",
            "  -7.23802969e-02  6.72677457e-02  5.40009104e-02 -8.82708877e-02\n",
            "  -9.48225036e-02 -4.16330472e-02  1.11101298e-02  4.89402376e-03\n",
            "   3.09943315e-02  6.18174262e-02 -5.32024577e-02  3.24316509e-02\n",
            "  -3.88149135e-02  2.31842864e-02 -2.81297904e-03 -3.73770110e-02\n",
            "  -6.26071617e-02 -2.20012367e-02 -1.72519579e-03  1.03363305e-01\n",
            "  -5.47040440e-02  4.70698103e-02  2.73341164e-02 -3.72476764e-02\n",
            "  -6.90491358e-03 -4.82539497e-02  4.59846780e-02 -4.90726978e-02\n",
            "  -3.01300883e-02 -2.89490055e-02  3.17230970e-02  6.68863580e-02\n",
            "  -1.41959367e-02  7.58978128e-02  1.65919792e-02  1.04179636e-01\n",
            "  -4.21793461e-02  2.60824393e-02  3.10045574e-02 -4.25525084e-02\n",
            "  -1.90855954e-02 -2.93722581e-02 -6.37147278e-02 -2.45957691e-02\n",
            "  -2.85304412e-02  3.54192629e-02 -4.08651121e-02  5.81426127e-03\n",
            "   8.23812634e-02  3.26108630e-03  3.11811864e-02 -3.80185544e-02\n",
            "   2.16928087e-02 -7.43319979e-03  4.61075343e-02 -3.72890905e-02\n",
            "  -2.30689142e-02 -3.26360725e-02 -5.67682907e-02 -2.39231829e-02\n",
            "   6.74895793e-02  1.01416958e-02  1.90340001e-02  1.80256180e-02\n",
            "   6.71907738e-02  9.26855113e-03 -7.28064030e-02 -2.94844843e-02\n",
            "  -2.20977180e-02 -3.33367735e-02  3.82499173e-02  4.15171571e-02\n",
            "  -4.14510034e-02 -7.14882761e-02  4.13339920e-02  2.89827920e-02\n",
            "  -4.07406242e-06 -7.40425065e-02  6.65657921e-03  8.49623978e-03\n",
            "  -7.24824294e-02 -5.59931323e-02  5.95660589e-04 -6.11735834e-03\n",
            "  -3.35865356e-02  3.55748343e-03  2.41048858e-02 -1.57586448e-02\n",
            "   3.27728651e-02  7.71152377e-02  7.02363206e-03 -3.13840769e-02\n",
            "  -7.71562457e-02 -5.64544275e-02  1.74520016e-02  4.91298735e-02\n",
            "  -8.10368806e-02  2.10891683e-02 -4.04082499e-02 -2.88767763e-03\n",
            "   4.01595272e-02  2.28060596e-02  3.83489169e-02 -7.37585053e-02\n",
            "  -9.80521813e-02 -1.53557146e-02 -5.51318377e-02  2.17683241e-02\n",
            "  -9.19746906e-02  3.01940311e-02  1.41931570e-03 -1.15337002e-03\n",
            "  -3.12948935e-02  1.38553027e-02  3.28962039e-03  2.55961232e-02\n",
            "  -4.92589362e-03 -3.89230326e-02  2.61092260e-02 -6.54028580e-02\n",
            "   6.38111234e-02  5.69475144e-02 -3.15414090e-03 -7.54501820e-02\n",
            "  -2.28602607e-02 -2.64068730e-02 -9.70430002e-02  3.85353118e-02\n",
            "   1.85709074e-02 -6.66959509e-02 -3.70545015e-02  8.27716365e-02\n",
            "  -3.84048745e-02  3.41351926e-02 -9.85209271e-02 -3.24625373e-02\n",
            "  -5.78852072e-02  3.86500210e-02  4.31780443e-02  2.49577351e-02\n",
            "  -3.31829153e-02  1.24967294e-02 -2.18769579e-04  3.47556099e-02\n",
            "  -1.95759591e-02 -1.05974056e-01  2.56895106e-02 -4.45117727e-02\n",
            "  -1.85238682e-02 -1.67316739e-02 -2.47752648e-02 -7.21923560e-02\n",
            "  -4.93568704e-02  5.67485578e-03 -4.06870060e-02 -2.55157165e-02\n",
            "  -3.64671163e-02  5.05664200e-02  7.32817277e-02 -8.63996148e-03\n",
            "   3.93536836e-02 -3.34311500e-02  6.03819564e-02  1.39662679e-02\n",
            "   3.53739560e-02 -8.90377723e-03  4.59648063e-03 -4.32675779e-02\n",
            "   2.14483682e-03 -9.44860727e-02  1.61788967e-02 -6.86139539e-02\n",
            "  -5.86694665e-02  2.87320907e-03  9.22455732e-03  4.90848832e-02\n",
            "  -5.22798300e-02  4.72008996e-02  3.48760523e-02 -3.84825952e-02\n",
            "   1.02138976e-02  4.79665399e-02  3.40327658e-02 -3.32646482e-02\n",
            "   3.14922594e-02  3.64791378e-02  1.53155485e-02 -9.71562192e-02\n",
            "  -7.40751298e-03 -9.85972285e-02 -8.43001530e-02 -7.17975246e-03\n",
            "   1.90600045e-02 -5.32503752e-03  3.90672237e-02  1.00903269e-02\n",
            "   2.43073404e-02  6.82938518e-03 -1.32313725e-02  5.88762611e-02\n",
            "   3.35316435e-02 -1.46035654e-02  2.31467038e-02  7.77961267e-03\n",
            "   2.41037421e-02  4.82568219e-02 -4.38138954e-02  7.78268790e-03\n",
            "   4.59212624e-02  3.69006880e-02 -1.17429402e-02 -4.46420396e-03\n",
            "   7.83799961e-03 -6.61487132e-02  5.45003393e-04  4.02018093e-02\n",
            "  -2.64081042e-02  3.04416697e-02 -6.51315376e-02  5.57356328e-02\n",
            "  -4.47253212e-02 -7.74192512e-02 -5.12564406e-02  9.08388000e-04\n",
            "   6.20976882e-03  2.24201214e-02  1.85031984e-02  4.52402085e-02\n",
            "   1.01687852e-03 -2.40422506e-02  8.45768303e-02 -5.08780964e-02\n",
            "  -3.45358299e-03 -6.48599537e-03 -1.08858727e-01  1.12834619e-02\n",
            "  -5.64255565e-03  4.32399027e-02  4.50733490e-03 -7.15910345e-02\n",
            "   2.71526985e-02 -5.62557019e-02  4.33727503e-02  3.62941921e-02\n",
            "   2.20444445e-02  6.03780197e-03  5.13474680e-02 -2.36744303e-02\n",
            "  -2.15599015e-02 -4.04884256e-02 -1.01267256e-01  1.89443342e-02\n",
            "   7.56918788e-02 -8.41497332e-02  3.43204923e-02 -1.59713032e-03\n",
            "  -2.58260313e-02 -7.61800483e-02 -1.12202959e-02  6.65166974e-02]], shape=(1, 512), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To implement a simple neural machine translation (NMT) model in Python, we can use the TensorFlow and Keras libraries. TensorFlow is a popular deep learning framework that provides tools for building and training neural networks, while Keras is a high-level neural networks API that runs on top of TensorFlow.\n",
        "\n",
        "Here's a step-by-step explanation and implementation of a simple NMT model using TensorFlow and Keras:"
      ],
      "metadata": {
        "id": "bn-qlYk7sQIe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense"
      ],
      "metadata": {
        "id": "Yukl1bldlsE3"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare Data: We need a dataset containing pairs of sentences in two languages (source and target). For simplicity, we'll use dummy data."
      ],
      "metadata": {
        "id": "4BbpuMrmsuAQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dummy data\n",
        "input_texts = ['hello', 'good morning', 'how are you']\n",
        "target_texts = ['bonjour', 'bonjour', 'comment ça va']\n",
        "\n",
        "# Generate vocabulary\n",
        "input_vocab = set()\n",
        "target_vocab = set()\n",
        "for input_text, target_text in zip(input_texts, target_texts):\n",
        "    input_vocab.update(input_text)\n",
        "    target_vocab.update(target_text)\n",
        "\n",
        "input_vocab = sorted(input_vocab)\n",
        "target_vocab = sorted(target_vocab)\n",
        "\n",
        "# Add special tokens for padding and start/end of sequence\n",
        "input_vocab_size = len(input_vocab) + 2\n",
        "target_vocab_size = len(target_vocab) + 2\n",
        "\n",
        "# Create dictionaries to map characters to indices and vice versa\n",
        "input_token_index = dict([(char, i+1) for i, char in enumerate(input_vocab)])\n",
        "target_token_index = dict([(char, i+1) for i, char in enumerate(target_vocab)])\n",
        "\n",
        "reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())\n",
        "\n",
        "# Define maximum sequence lengths\n",
        "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
        "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
        "\n",
        "# Initialize arrays for encoder and decoder inputs\n",
        "encoder_input_data = np.zeros((len(input_texts), max_encoder_seq_length, input_vocab_size), dtype='float32')\n",
        "decoder_input_data = np.zeros((len(input_texts), max_decoder_seq_length, target_vocab_size), dtype='float32')\n",
        "decoder_target_data = np.zeros((len(input_texts), max_decoder_seq_length, target_vocab_size), dtype='float32')\n",
        "\n",
        "# Fill the arrays with one-hot encoding\n",
        "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        encoder_input_data[i, t, input_token_index[char]] = 1.0\n",
        "    for t, char in enumerate(target_text):\n",
        "        decoder_input_data[i, t, target_token_index[char]] = 1.0\n",
        "        if t > 0:\n",
        "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n"
      ],
      "metadata": {
        "id": "MOy5eorzmEXU"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the Model: We'll create a simple sequence-to-sequence model with an LSTM encoder and decoder."
      ],
      "metadata": {
        "id": "a76O-NzIs10Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define input sequence\n",
        "encoder_inputs = Input(shape=(None, input_vocab_size))\n",
        "# LSTM encoding\n",
        "encoder = LSTM(256, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
        "# Discard encoder outputs, we only need the states\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# Set up the decoder, using encoder_states as initial state\n",
        "decoder_inputs = Input(shape=(None, target_vocab_size))\n",
        "# We set up our decoder to return full output sequences and to return internal states as well\n",
        "decoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "decoder_dense = Dense(target_vocab_size, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model that will turn\n",
        "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n"
      ],
      "metadata": {
        "id": "xS4kvFmJmIMZ"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compile and Train the Model: Compile the model with appropriate loss function and optimizer, then fit the model to the data."
      ],
      "metadata": {
        "id": "m3pRtKDRs99Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
        "model.fit([encoder_input_data, decoder_input_data], decoder_target_data, batch_size=1, epochs=50, validation_split=0.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gVtNvrFmLwJ",
        "outputId": "b9ef3887-feed-4d93-b7c2-61486d9e50ea"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "2/2 [==============================] - 4s 1s/step - loss: 1.2676 - val_loss: 2.5636\n",
            "Epoch 2/50\n",
            "2/2 [==============================] - 0s 91ms/step - loss: 1.2222 - val_loss: 2.5753\n",
            "Epoch 3/50\n",
            "2/2 [==============================] - 0s 97ms/step - loss: 1.1608 - val_loss: 2.6765\n",
            "Epoch 4/50\n",
            "2/2 [==============================] - 0s 105ms/step - loss: 0.9860 - val_loss: 2.9888\n",
            "Epoch 5/50\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 0.7581 - val_loss: 2.9783\n",
            "Epoch 6/50\n",
            "2/2 [==============================] - 0s 98ms/step - loss: 0.6612 - val_loss: 3.0365\n",
            "Epoch 7/50\n",
            "2/2 [==============================] - 0s 110ms/step - loss: 0.5937 - val_loss: 3.2744\n",
            "Epoch 8/50\n",
            "2/2 [==============================] - 0s 120ms/step - loss: 0.5306 - val_loss: 3.1573\n",
            "Epoch 9/50\n",
            "2/2 [==============================] - 0s 145ms/step - loss: 0.5890 - val_loss: 3.5419\n",
            "Epoch 10/50\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.4633 - val_loss: 3.5553\n",
            "Epoch 11/50\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.4380 - val_loss: 3.6005\n",
            "Epoch 12/50\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.4994 - val_loss: 3.7645\n",
            "Epoch 13/50\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 0.5144 - val_loss: 3.5281\n",
            "Epoch 14/50\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.4292 - val_loss: 3.6488\n",
            "Epoch 15/50\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.3893 - val_loss: 3.3874\n",
            "Epoch 16/50\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.4906 - val_loss: 3.7700\n",
            "Epoch 17/50\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.3658 - val_loss: 3.8665\n",
            "Epoch 18/50\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.4504 - val_loss: 3.6383\n",
            "Epoch 19/50\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.3617 - val_loss: 3.6916\n",
            "Epoch 20/50\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.3366 - val_loss: 3.5291\n",
            "Epoch 21/50\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.4122 - val_loss: 3.7942\n",
            "Epoch 22/50\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.3103 - val_loss: 3.6386\n",
            "Epoch 23/50\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.3507 - val_loss: 3.5251\n",
            "Epoch 24/50\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.4078 - val_loss: 3.8488\n",
            "Epoch 25/50\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.2887 - val_loss: 3.8408\n",
            "Epoch 26/50\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.2877 - val_loss: 3.9479\n",
            "Epoch 27/50\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.3778 - val_loss: 3.7542\n",
            "Epoch 28/50\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.2884 - val_loss: 3.8105\n",
            "Epoch 29/50\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.2600 - val_loss: 3.7580\n",
            "Epoch 30/50\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.2736 - val_loss: 3.5459\n",
            "Epoch 31/50\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.3718 - val_loss: 3.8667\n",
            "Epoch 32/50\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.2514 - val_loss: 3.8416\n",
            "Epoch 33/50\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.2417 - val_loss: 3.7437\n",
            "Epoch 34/50\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.2693 - val_loss: 3.5702\n",
            "Epoch 35/50\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.3542 - val_loss: 3.8674\n",
            "Epoch 36/50\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.2393 - val_loss: 3.8138\n",
            "Epoch 37/50\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.2408 - val_loss: 3.6865\n",
            "Epoch 38/50\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.2852 - val_loss: 3.7563\n",
            "Epoch 39/50\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.2489 - val_loss: 3.7234\n",
            "Epoch 40/50\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.2638 - val_loss: 3.8261\n",
            "Epoch 41/50\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 0.2307 - val_loss: 3.6986\n",
            "Epoch 42/50\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.2706 - val_loss: 3.8602\n",
            "Epoch 43/50\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.2205 - val_loss: 3.8773\n",
            "Epoch 44/50\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.2173 - val_loss: 3.7328\n",
            "Epoch 45/50\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.2561 - val_loss: 3.8198\n",
            "Epoch 46/50\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.2285 - val_loss: 3.7030\n",
            "Epoch 47/50\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.2672 - val_loss: 3.9165\n",
            "Epoch 48/50\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.2103 - val_loss: 3.9466\n",
            "Epoch 49/50\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.2051 - val_loss: 3.8937\n",
            "Epoch 50/50\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.2066 - val_loss: 3.8618\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d9250c2bfa0>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inference: To test the model, we need to set up the inference mode separately."
      ],
      "metadata": {
        "id": "2nKit3lgtHXy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define encoder model\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "# Define decoder model\n",
        "decoder_state_input_h = Input(shape=(256,))\n",
        "decoder_state_input_c = Input(shape=(256,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(\n",
        "    decoder_inputs, initial_state=decoder_states_inputs)\n",
        "decoder_states = [state_h, state_c]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs] + decoder_states)\n"
      ],
      "metadata": {
        "id": "bllb2jqMmO4b"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "source": [
        "print(target_token_index)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2-HSUjrn6-4",
        "outputId": "bc6f7d3a-762d-42ed-8929-3e3730ecaf04"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{' ': 1, 'a': 2, 'b': 3, 'c': 4, 'e': 5, 'j': 6, 'm': 7, 'n': 8, 'o': 9, 'r': 10, 't': 11, 'u': 12, 'v': 13, 'ç': 14}\n"
          ]
        }
      ]
    },
    {
      "source": [
        "if '\\t' not in target_token_index:\n",
        "    print('The character \"\\t\" is not present in the target_token_index dictionary.')"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtt20jFQn7Ut",
        "outputId": "bdb549c7-3d9c-4aae-b13b-8609d118bf01"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The character \"\t\" is not present in the target_token_index dictionary.\n"
          ]
        }
      ]
    },
    {
      "source": [
        "target_token_index['\\t'] = len(target_token_index) + 1"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "FE_tyV9Rn8Ch"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To evaluate the performance and check the accuracy of the neural machine translation (NMT) model, we can perform inference on the test data and calculate the accuracy based on the model's predictions compared to the ground truth translations."
      ],
      "metadata": {
        "id": "t23HEbNhtSBn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to decode sequences\n",
        "def decode_sequence(input_seq):\n",
        "    # Encode the input sequence to get the internal state vectors\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    # Generate empty target sequence of length 1\n",
        "    target_seq = np.zeros((1, 1, target_vocab_size))\n",
        "    # Populate the first character of target sequence with the start character\n",
        "    target_seq[0, 0, target_token_index['\\t']] = 1.0\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += sampled_char\n",
        "\n",
        "        # Exit condition: either hit max length or find stop character\n",
        "        if (sampled_char == '\\n' or len(decoded_sentence) > max_decoder_seq_length):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (length 1).\n",
        "        target_seq = np.zeros((1, 1, target_vocab_size))\n",
        "        target_seq[0, 0, sampled_token_index] = 1.0\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence\n",
        "\n",
        "# Define test data\n",
        "test_input_texts = ['hello', 'good morning', 'how are you']\n",
        "test_target_texts = ['bonjour', 'bonjour', 'comment ça va']\n",
        "\n",
        "# Initialize variables for accuracy calculation\n",
        "total_samples = len(test_input_texts)\n",
        "correct_predictions = 0\n",
        "\n",
        "# Iterate through test data\n",
        "for input_text, target_text in zip(test_input_texts, test_target_texts):\n",
        "    # Convert input sequence to one-hot encoding\n",
        "    encoder_input_data = np.zeros((1, max_encoder_seq_length, input_vocab_size), dtype='float32')\n",
        "    for t, char in enumerate(input_text):\n",
        "        encoder_input_data[0, t, input_token_index[char]] = 1.0\n",
        "\n",
        "    # Decode the input sequence\n",
        "    decoded_sentence = decode_sequence(encoder_input_data)\n",
        "\n",
        "    # Print the input, target, and predicted translations\n",
        "    print('Input:', input_text)\n",
        "    print('Target:', target_text)\n",
        "    print('Predicted:', decoded_sentence)\n",
        "\n",
        "    # Update accuracy count\n",
        "    if decoded_sentence.strip() == target_text.strip():\n",
        "        correct_predictions += 1\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = (correct_predictions / total_samples) * 100\n",
        "print('Accuracy:', accuracy, '%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6motK8dinpSE",
        "outputId": "678063e3-7e79-4a80-d332-32ec7c3bc02a"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Input: hello\n",
            "Target: bonjour\n",
            "Predicted: onjouroooooooo\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Input: good morning\n",
            "Target: bonjour\n",
            "Predicted: onjouroooooooo\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Input: how are you\n",
            "Target: comment ça va\n",
            "Predicted: onjouroooooooo\n",
            "Accuracy: 0.0 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code will perform inference on the test data, printing the input, target, and predicted translations for each example. Finally, it will calculate and print the accuracy of the model's translations compared to the ground truth translations.\n",
        "\n",
        "Ensure that the model has been trained properly on suitable data and adjust the code accordingly if your dataset or model architecture differs."
      ],
      "metadata": {
        "id": "0Ro9ByHJtdM8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2nd Part :-\n",
        "To implement another simple neural machine translation (NMT) model in Python, we can use the PyTorch library. PyTorch is a popular deep learning framework known for its flexibility and ease of use. Create a basic sequence-to-sequence model with an encoder and decoder architecture.\n",
        "\n",
        "Here's the step-by-step explanation and implementation:\n",
        "\n",
        "Import Libraries: We start by importing the necessary libraries."
      ],
      "metadata": {
        "id": "RqCamJJitthG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "agnQShqirARB"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare Data: We need a dataset containing pairs of sentences in two languages (source and target). For simplicity, use dummy data similar to the previous example."
      ],
      "metadata": {
        "id": "Auzp5_g_ui04"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dummy data\n",
        "input_texts = ['hello', 'good morning', 'how are you']\n",
        "target_texts = ['bonjour', 'bonjour', 'comment ça va']\n",
        "\n",
        "# Generate vocabulary\n",
        "input_vocab = set()\n",
        "target_vocab = set()\n",
        "for input_text, target_text in zip(input_texts, target_texts):\n",
        "    input_vocab.update(input_text)\n",
        "    target_vocab.update(target_text)\n",
        "\n",
        "input_vocab = sorted(input_vocab)\n",
        "target_vocab = sorted(target_vocab)\n",
        "\n",
        "# Add special tokens for padding and start/end of sequence\n",
        "input_vocab_size = len(input_vocab) + 2\n",
        "target_vocab_size = len(target_vocab) + 2\n",
        "\n",
        "# Create dictionaries to map characters to indices and vice versa\n",
        "input_token_index = dict([(char, i+1) for i, char in enumerate(input_vocab)])\n",
        "target_token_index = dict([(char, i+1) for i, char in enumerate(target_vocab)])\n",
        "\n",
        "reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())\n",
        "\n",
        "# Define maximum sequence lengths\n",
        "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
        "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
        "\n",
        "# Initialize arrays for encoder and decoder inputs\n",
        "encoder_input_data = np.zeros((len(input_texts), max_encoder_seq_length, input_vocab_size), dtype='float32')\n",
        "decoder_input_data = np.zeros((len(input_texts), max_decoder_seq_length, target_vocab_size), dtype='float32')\n",
        "decoder_target_data = np.zeros((len(input_texts), max_decoder_seq_length, target_vocab_size), dtype='float32')\n",
        "\n",
        "# Fill the arrays with one-hot encoding\n",
        "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        encoder_input_data[i, t, input_token_index[char]] = 1.0\n",
        "    for t, char in enumerate(target_text):\n",
        "        decoder_input_data[i, t, target_token_index[char]] = 1.0\n",
        "        if t > 0:\n",
        "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.0"
      ],
      "metadata": {
        "id": "GXoqHdVtrPtt"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the Model: Create a simple sequence-to-sequence model with an encoder and decoder architecture using PyTorch."
      ],
      "metadata": {
        "id": "-oTwWZpXumw-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output, hidden = self.gru(embedded)\n",
        "        return output, hidden\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = nn.functional.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden"
      ],
      "metadata": {
        "id": "xyjoG_x-rTyq"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the Model: Need to define functions for training the model."
      ],
      "metadata": {
        "id": "ZkliPZO7vDNP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=max_decoder_seq_length):\n",
        "    encoder_hidden = encoder.init_hidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]])\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    for di in range(target_length):\n",
        "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "        topv, topi = decoder_output.topk(1)\n",
        "        decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        loss += criterion(decoder_output, target_tensor[di])\n",
        "        if decoder_input.item() == EOS_token:\n",
        "            break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length\n",
        "\n",
        "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        training_pair = tensorsFromPair(random.choice(pairs))\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        loss = train(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('(%d %d%%) %.4f' % (iter, iter / n_iters * 100, print_loss_avg))"
      ],
      "metadata": {
        "id": "VVnsHMmrrYWd"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inference: Need to define functions for inference and evaluation."
      ],
      "metadata": {
        "id": "QmRdSayWvJQF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(encoder, decoder, sentence, max_length=max_decoder_seq_length):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.init_hidden()\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]])\n",
        "        decoder_hidden = encoder_hidden\n",
        "        decoded_words = []\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words"
      ],
      "metadata": {
        "id": "aVchyPWdrdAr"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conclusion: This implementation provides a basic understanding of how an NMT model works using a sequence-to-sequence architecture with an encoder and decoder. To evaluate the model's performance, we can perform inference on the test data, compare the predicted translations with the ground truth translations, and compute the error rate or accuracy."
      ],
      "metadata": {
        "id": "XtkZV5_6vXGG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, to perform inference and check the accuracy by computing the error rate, you need to train the model using the provided training data, then evaluate it on the test data. You'll compare the model's predictions with the actual translations and calculate the accuracy accordingly.\n",
        "\n",
        "Ensure that the model is trained properly and adjust the code accordingly if your dataset or model architecture differs."
      ],
      "metadata": {
        "id": "g4dm9zYsviSU"
      }
    },
    {
      "source": [
        "!ls"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERw0mVtgxRfQ",
        "outputId": "675dee6c-8bda-4a94-f803-c4311887fbee"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data\n"
          ]
        }
      ]
    },
    {
      "source": [
        "import os\n",
        "print(os.getcwd())"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnS8gxtYxSzc",
        "outputId": "8683065f-41bd-4ad6-f0fe-f4415d3bf6c8"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "source": [
        "!pip show torch"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sz7OD6XhxTYv",
        "outputId": "4e1d4ce8-39ae-42db-e04f-a01dea2e24e6"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: torch\n",
            "Version: 2.1.0+cu121\n",
            "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
            "Home-page: https://pytorch.org/\n",
            "Author: PyTorch Team\n",
            "Author-email: packages@pytorch.org\n",
            "License: BSD-3\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: filelock, fsspec, jinja2, networkx, sympy, triton, typing-extensions\n",
            "Required-by: fastai, torchaudio, torchdata, torchtext, torchvision\n"
          ]
        }
      ]
    }
  ]
}